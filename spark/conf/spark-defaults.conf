# ============================
# Spark Cluster Configuration
# ============================

# Master URL máº·c Ä‘á»‹nh (Spark Master container)
spark.master spark://spark-master:7077

# App name máº·c Ä‘á»‹nh
spark.app.name SparkApp

# NÆ¡i Spark lÆ°u cache táº¡m & shuffle data
spark.local.dir /tmp/spark

# Ivy cache (táº£i package jar bÃªn ngoÃ i náº¿u cáº§n)
spark.jars.ivy /tmp/.ivy2
spark.jars.packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0

# Fix cá»•ng máº¡ng driver Ä‘á»ƒ worker káº¿t ná»‘i á»•n Ä‘á»‹nh (trÃ¡nh random)
spark.driver.host spark-master
spark.driver.port 40443
spark.blockManager.port 6060

# Ã‰p dÃ¹ng LZ4 thay vÃ¬ ZSTD Ä‘á»ƒ trÃ¡nh lá»—i native zstd-jni
spark.io.compression.codec lz4
spark.shuffle.mapStatus.compression.codec lz4

# ============================
# Spark SQL Config
# ============================

# Sá»‘ lÆ°á»£ng partitions khi shuffle (tá»‘i Æ°u cho mÃ¡y local nhá»)
spark.sql.shuffle.partitions 4

# LuÃ´n dÃ¹ng local filesystem, trÃ¡nh HDFS/Kerberos
spark.hadoop.fs.defaultFS file:///
spark.sql.warehouse.dir file:///tmp/spark-warehouse
spark.hadoop.fs.viewfs.impl.disable true
spark.hadoop.fs.AbstractFileSystem.viewfs.impl org.apache.hadoop.fs.UnsupportedFileSystem

# VÃ´ hiá»‡u hÃ³a Kerberos hoÃ n toÃ n
spark.hadoop.hadoop.security.authentication Simple
spark.hadoop.hadoop.security.authorization false

# Äá»‹nh nghÄ©a rÃµ rÃ ng user name cho HDFS, dÃ¹ khÃ´ng dÃ¹ng
spark.hadoop.fs.hdfs.impl.disable.cache true
spark.hadoop.fs.hdfs.impl org.apache.hadoop.fs.RawLocalFileSystem

# ============================
# Memory Config
# ============================

# Tuá»³ RAM mÃ¡y báº¡n, cÃ³ thá»ƒ chá»‰nh lÃªn 2G/4G náº¿u cáº§n
spark.driver.memory 1G
spark.executor.memory 1G
